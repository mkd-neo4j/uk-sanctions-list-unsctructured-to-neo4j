# UK Sanctions List: Unstructured to Neo4j

Transform unstructured UK sanctions PDF data into a structured Neo4j graph database for
fraud detection and compliance.

## ğŸ¯ Overview

This project demonstrates how to process the UK List of Financial Sanctions Targets
(Cyber regime) from an unstructured PDF format into a structured graph database
suitable for:
- Compliance checks
- Relationship analysis
- Fraud pattern detection
- Integration with existing fraud detection systems

## ğŸš€ Quick Start

### Prerequisites
- Python 3.x
- Virtual environment (recommended)

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd uk-sanctions-list-unsctructured-to-neo4j

# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Run the Pipeline

```bash
python main.py
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py              # Main entry point - orchestrates the pipeline
â”œâ”€â”€ pdf_to_text.py       # Step 1: PDF to text conversion module
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ pdf/
â”‚   â””â”€â”€ Cyber.pdf       # UK sanctions list (Cyber regime)
â”œâ”€â”€ output/
â”‚   â””â”€â”€ Cyber_text.txt  # Extracted text from PDF
â””â”€â”€ WHY.md              # Detailed project rationale
```

## ğŸ”„ Pipeline Steps

### Step 1: PDF to Text Conversion âœ…
- **Status**: Implemented
- **Module**: `pdf_to_text.py`
- **Function**: Extracts raw text from the sanctions PDF
- **Output**: `output/Cyber_text.txt`

### Step 2: LLM Parsing ğŸ”„
- **Status**: Coming soon
- **Purpose**: Use language models to identify and extract individuals and entities
- **Expected output**: Structured JSON with parsed entities

### Step 3: Data Modeling ğŸ”„
- **Status**: Coming soon
- **Purpose**: Create Pydantic models for validation
- **Models**:
- Individual sanctions records
- Entity sanctions records

### Step 4: Neo4j Loading ğŸ”„
- **Status**: Coming soon
- **Purpose**: Load structured data into Neo4j
- **Schema**: Based on [Neo4j Transactional Data Model](https://neo4j.com/developer/industry-use-cases/data-models/transactions/transactions-base-model/)

## ğŸ“Š Current Implementation

### PDF Processing Results
- **Source**: `pdf/Cyber.pdf`
- **Pages**: 13
- **Content**:
- 70 sanctioned individuals
- 9 sanctioned entities
- **Extracted characters**: 86,443

### Sample Data Structure
The PDF contains structured fields including:
- Names and aliases (AKAs)
- Group IDs
- Last Updated dates
- Passport numbers
- Addresses
- Statement of Reasons
- Other metadata

## ğŸ›  Technologies

- **PDF Processing**: pdfplumber 0.11.4
- **Future additions**:
- LLM integration (OpenAI/Anthropic)
- Pydantic for data validation
- Neo4j Python driver

## ğŸ“‹ Requirements

See `requirements.txt` for full list. Core dependencies:
```
pdfplumber==0.11.4
```

## ğŸ“ˆ Next Steps

1. Implement LLM-based entity extraction
2. Design Pydantic models for data validation
3. Create Neo4j schema and loading logic
4. Add error handling and logging
5. Implement incremental updates for new sanctions